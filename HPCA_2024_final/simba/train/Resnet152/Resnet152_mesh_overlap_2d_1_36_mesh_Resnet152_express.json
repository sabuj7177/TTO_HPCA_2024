{
    "configuration": {
        "arch_config": "/scratch/user/sabuj.laskar/MeshFermat/src/SCALE-Sim/configs/express.cfg",
        "num_hmcs": 36,
        "num_vaults": 16,
        "mini_batch_size": 576,
        "network": "/scratch/user/sabuj.laskar/MeshFermat/src/SCALE-Sim/topologies/mlperf/Resnet152.csv",
        "run_name": "Resnet152",
        "outdir": "/scratch/user/sabuj.laskar/MeshFermat/results/HPCA2024/simbatrain/outputs/Resnet152",
        "dump": false,
        "allreduce": "mesh_overlap_2d_1",
        "booksim_config": "/scratch/user/sabuj.laskar/MeshFermat/src/booksim2/runfiles/mesh/anynet_mesh_36_200.cfg",
        "booksim_network": "mesh",
        "verbose": true,
        "only_compute": true,
        "only_allreduce": false,
        "only_reduce_scatter": false,
        "only_all_gather": false,
        "message_buffer_size": 32,
        "message_size": 8192,
        "sub_message_size": 8192,
        "synthetic_data_size": 0,
        "flits_per_packet": 16,
        "bandwidth": 200,
        "load_tree": false,
        "kary": 5,
        "radix": 4,
        "chunk_size": 12288,
        "strict_schedule": true,
        "prioritize_schedule": true,
        "oracle_lockstep": false,
        "estimate_lockstep": false,
        "enable_logger": [],
        "save_link_utilization": false,
        "layer_by_layer": false,
        "layer_number": "0",
        "latency": 21,
        "per_message_time": 357,
        "layer_number_list": [
            0
        ],
        "pe_array_height": 32,
        "pe_array_width": 32,
        "ifmap_sram_size": 1048576,
        "filter_sram_size": 1048576,
        "ofmap_sram_size": 1048576,
        "ifmap_offset": 0,
        "filter_offset": 10000000,
        "ofmap_offset": 20000000,
        "ifmap_grad_offset": 40000000,
        "filter_grad_offset": 50000000,
        "ofmap_grad_offset": 30000000,
        "data_flow": "os",
        "logdir": "/scratch/user/sabuj.laskar/MeshFermat/results/HPCA2024/simbatrain/outputs/Resnet152",
        "total_partial_trees": 4887,
        "partial_tree_message": 2,
        "nodes": 36
    },
    "results": {
        "performance": {
            "training": 40658924,
            "training_by_layer": {
                "155": 11229884,
                "154": 11345658,
                "153": 11566929,
                "152": 11682703,
                "151": 11798477,
                "150": 12019748,
                "149": 12135522,
                "148": 12694688,
                "147": 12810462,
                "146": 13409564,
                "145": 13624666,
                "144": 13732248,
                "143": 13944278,
                "142": 14051860,
                "141": 14159442,
                "140": 14371472,
                "139": 14479054,
                "138": 14586636,
                "137": 14798666,
                "136": 14906248,
                "135": 15013830,
                "134": 15225860,
                "133": 15333442,
                "132": 15441024,
                "131": 15653054,
                "130": 15760636,
                "129": 15868218,
                "128": 16080248,
                "127": 16187830,
                "126": 16295412,
                "125": 16507442,
                "124": 16615024,
                "123": 16722606,
                "122": 16934636,
                "121": 17042218,
                "120": 17149800,
                "119": 17361830,
                "118": 17469412,
                "117": 17576994,
                "116": 17789024,
                "115": 17896606,
                "114": 18004188,
                "113": 18216218,
                "112": 18323800,
                "111": 18431382,
                "110": 18643412,
                "109": 18750994,
                "108": 18858576,
                "107": 19070606,
                "106": 19178188,
                "105": 19285770,
                "104": 19497800,
                "103": 19605382,
                "102": 19712964,
                "101": 19924994,
                "100": 20032576,
                "99": 20140158,
                "98": 20352188,
                "97": 20459770,
                "96": 20567352,
                "95": 20779382,
                "94": 20886964,
                "93": 20994546,
                "92": 21206576,
                "91": 21314158,
                "90": 21421740,
                "89": 21633770,
                "88": 21741352,
                "87": 21848934,
                "86": 22060964,
                "85": 22168546,
                "84": 22276128,
                "83": 22488158,
                "82": 22595740,
                "81": 22703322,
                "80": 22915352,
                "79": 23022934,
                "78": 23130516,
                "77": 23342546,
                "76": 23450128,
                "75": 23557710,
                "74": 23769740,
                "73": 23877322,
                "72": 23984904,
                "71": 24196934,
                "70": 24304516,
                "69": 24412098,
                "68": 24624128,
                "67": 24731710,
                "66": 24839292,
                "65": 25051322,
                "64": 25158904,
                "63": 25266486,
                "62": 25478516,
                "61": 25586098,
                "60": 25693680,
                "59": 25905710,
                "58": 26013292,
                "57": 26120874,
                "56": 26332904,
                "55": 26440486,
                "54": 26548068,
                "53": 26760098,
                "52": 26867680,
                "51": 26975262,
                "50": 27187292,
                "49": 27294874,
                "48": 27402456,
                "47": 27614486,
                "46": 27722068,
                "45": 27829650,
                "44": 28041680,
                "43": 28149262,
                "42": 28256844,
                "41": 28468874,
                "40": 28576456,
                "39": 29086470,
                "38": 29194052,
                "37": 29752258,
                "36": 29955072,
                "35": 30056510,
                "34": 30269116,
                "33": 30370554,
                "32": 30471992,
                "31": 30684598,
                "30": 30786036,
                "29": 30887474,
                "28": 31100080,
                "27": 31201518,
                "26": 31302956,
                "25": 31515562,
                "24": 31617000,
                "23": 31718438,
                "22": 31931044,
                "21": 32032482,
                "20": 32133920,
                "19": 32346526,
                "18": 32447964,
                "17": 32549402,
                "16": 32762008,
                "15": 32863446,
                "14": 33365268,
                "13": 33466706,
                "12": 34023328,
                "11": 34224094,
                "10": 34324508,
                "9": 34542443,
                "8": 34642858,
                "7": 34743272,
                "6": 34961207,
                "5": 35061622,
                "4": 35162036,
                "3": 35262450,
                "2": 35480385,
                "1": 35505536,
                "0": 40541657
            },
            "allreduce": {
                "computation": 0,
                "pure_communication": 1,
                "total": 1
            },
            "total": 40658925
        },
        "power": {
            "network": {
                "dynamic": NaN,
                "static": 6.608001860700779,
                "total": NaN,
                "router": {
                    "dynamic": NaN,
                    "static": 6.592026109020779,
                    "total": NaN
                },
                "link": {
                    "dynamic": NaN,
                    "static": 0.015975751679999987,
                    "total": NaN,
                    "flits": 0
                }
            }
        }
    }
}